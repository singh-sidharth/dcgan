{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines for DCGAN\n",
    "\n",
    "1. Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "2. Use batchnorm in both the generator and the discriminator.\n",
    "3. Reomve fully connected hidden layers for deeper architectures.\n",
    "4. Use ReLU activatoin in generator for all layers except for the output, which uses Tanh.\n",
    "5. Use LeakyReLU activation in the discriminator for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "# Data and utility imports\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ), # 32X32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2, 4, 2, 1), # 16X16\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0), # 1x1\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x z_dim x 1 x 1\n",
    "            self._block(z_dim, features_g*16, 4, 1, 0), # N x f_g*16  x 4 x 4\n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1),\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1),\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g*2, channels_img, kernel_size=4, stride=2, padding=1,\n",
    "            ),\n",
    "            nn.Tanh(), # [-1, 1]\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    initialize_weights(disc)\n",
    "    assert disc(x).shape == (N, 1,1,1)\n",
    "    gen = Generator(z_dim, in_channels, 8)\n",
    "    initialize_weights(gen)\n",
    "    z = torch.randn((N, z_dim, 1, 1))\n",
    "    assert gen(z).shape == (N, in_channels, H, W)\n",
    "    print(\"Success\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and misc\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LR = 2e-4\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 10\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(IMAGE_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)],\n",
    "            [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root='data/', train=True, transform=transforms, download=True\n",
    "    )\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch 0/469                   Loss D: 0.6880, loss G: 0.8021\n",
      "Epoch [1/10] Batch 100/469                   Loss D: 0.0145, loss G: 4.1541\n",
      "Epoch [1/10] Batch 200/469                   Loss D: 0.4589, loss G: 1.4357\n",
      "Epoch [1/10] Batch 300/469                   Loss D: 1.1093, loss G: 1.7831\n",
      "Epoch [1/10] Batch 400/469                   Loss D: 0.5253, loss G: 1.2052\n",
      "Epoch [2/10] Batch 0/469                   Loss D: 0.5822, loss G: 0.7517\n",
      "Epoch [2/10] Batch 100/469                   Loss D: 0.6052, loss G: 1.0300\n",
      "Epoch [2/10] Batch 200/469                   Loss D: 0.6625, loss G: 0.8317\n",
      "Epoch [2/10] Batch 300/469                   Loss D: 0.5789, loss G: 0.8591\n",
      "Epoch [2/10] Batch 400/469                   Loss D: 0.5235, loss G: 1.0581\n",
      "Epoch [3/10] Batch 0/469                   Loss D: 0.5431, loss G: 1.1493\n",
      "Epoch [3/10] Batch 100/469                   Loss D: 0.5199, loss G: 0.9826\n",
      "Epoch [3/10] Batch 200/469                   Loss D: 0.4622, loss G: 1.9445\n",
      "Epoch [3/10] Batch 300/469                   Loss D: 0.4304, loss G: 1.0829\n",
      "Epoch [3/10] Batch 400/469                   Loss D: 0.3828, loss G: 1.9493\n",
      "Epoch [4/10] Batch 0/469                   Loss D: 0.4504, loss G: 1.1620\n",
      "Epoch [4/10] Batch 100/469                   Loss D: 0.3154, loss G: 2.4617\n",
      "Epoch [4/10] Batch 200/469                   Loss D: 0.3923, loss G: 4.6867\n",
      "Epoch [4/10] Batch 300/469                   Loss D: 0.4410, loss G: 1.7508\n",
      "Epoch [4/10] Batch 400/469                   Loss D: 0.5492, loss G: 1.8073\n",
      "Epoch [5/10] Batch 0/469                   Loss D: 0.2111, loss G: 3.0389\n",
      "Epoch [5/10] Batch 100/469                   Loss D: 0.2668, loss G: 1.7845\n",
      "Epoch [5/10] Batch 200/469                   Loss D: 0.2634, loss G: 4.2276\n",
      "Epoch [5/10] Batch 300/469                   Loss D: 0.2750, loss G: 1.7464\n",
      "Epoch [5/10] Batch 400/469                   Loss D: 0.1739, loss G: 1.7750\n",
      "Epoch [6/10] Batch 0/469                   Loss D: 0.0871, loss G: 3.2833\n",
      "Epoch [6/10] Batch 100/469                   Loss D: 0.4497, loss G: 1.4698\n",
      "Epoch [6/10] Batch 200/469                   Loss D: 0.2857, loss G: 2.3028\n",
      "Epoch [6/10] Batch 300/469                   Loss D: 0.0784, loss G: 2.9293\n",
      "Epoch [6/10] Batch 400/469                   Loss D: 0.0663, loss G: 3.4862\n",
      "Epoch [7/10] Batch 0/469                   Loss D: 0.1075, loss G: 3.7504\n",
      "Epoch [7/10] Batch 100/469                   Loss D: 0.2163, loss G: 3.9806\n",
      "Epoch [7/10] Batch 200/469                   Loss D: 0.0700, loss G: 4.1832\n",
      "Epoch [7/10] Batch 300/469                   Loss D: 0.2617, loss G: 1.5105\n",
      "Epoch [7/10] Batch 400/469                   Loss D: 0.1784, loss G: 3.2968\n",
      "Epoch [8/10] Batch 0/469                   Loss D: 0.0471, loss G: 3.6241\n",
      "Epoch [8/10] Batch 100/469                   Loss D: 0.1801, loss G: 4.7631\n",
      "Epoch [8/10] Batch 200/469                   Loss D: 0.0934, loss G: 3.2653\n",
      "Epoch [8/10] Batch 300/469                   Loss D: 0.0671, loss G: 2.5732\n",
      "Epoch [8/10] Batch 400/469                   Loss D: 0.5231, loss G: 3.7404\n",
      "Epoch [9/10] Batch 0/469                   Loss D: 0.0801, loss G: 3.4927\n",
      "Epoch [9/10] Batch 100/469                   Loss D: 0.3707, loss G: 1.6987\n",
      "Epoch [9/10] Batch 200/469                   Loss D: 0.0991, loss G: 3.2745\n",
      "Epoch [9/10] Batch 300/469                   Loss D: 0.0455, loss G: 4.1520\n",
      "Epoch [9/10] Batch 400/469                   Loss D: 0.4204, loss G: 1.4891\n",
      "Epoch [10/10] Batch 0/469                   Loss D: 0.2571, loss G: 2.0695\n",
      "Epoch [10/10] Batch 100/469                   Loss D: 0.0488, loss G: 3.8264\n",
      "Epoch [10/10] Batch 200/469                   Loss D: 0.5386, loss G: 1.3995\n",
      "Epoch [10/10] Batch 300/469                   Loss D: 0.0522, loss G: 3.3998\n",
      "Epoch [10/10] Batch 400/469                   Loss D: 0.2571, loss G: 3.3449\n"
     ]
    }
   ],
   "source": [
    "# Initializing training\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"runs/real\")\n",
    "writer_fake = SummaryWriter(f\"runs/fake\")\n",
    "step = 0\n",
    "\n",
    "# Set training mode\n",
    "gen.train()\n",
    "disc.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # Train Discriminator max log(D(x)) + log(1 - D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph = True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train Generator min log(1 - D(G(z))) <=> max log(D(G(z)))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ff00def91cd6b45677128aecc6864cd1ffae2d05d5f28c8344a8a343848c1e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
